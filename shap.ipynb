{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b2047e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import warnings\n",
    "import os\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6848804",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetName = list(range(0,7))\n",
    "modelloML = ['lr','dt','rf','mlp']\n",
    "fileCSV = ['datasetArtisticBackgroundFINAL.csv', 'datasetScientificBackgroundFINAL.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1af2da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = ['lr',\n",
    "                'dt',\n",
    "                'rf',\n",
    "                'mlp']\n",
    "\n",
    "param_lr = [{'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}]\n",
    "\n",
    "param_dt = [{'max_depth': [5, 10, 15, 20, 25, 30]}]\n",
    "\n",
    "param_mlp = [{'hidden_layer_sizes': [(5,), (10,), (15,)],\n",
    "             'activation': ['tanh', 'relu'],\n",
    "             'solver': ['sgd', 'adam'],\n",
    "             'alpha': [0.0001, 0.05],\n",
    "             'learning_rate': ['constant','adaptive'],}]\n",
    "\n",
    "param_rf = [{'bootstrap': [True, False],\n",
    "             'max_depth': [10, 20, 30],\n",
    "             'max_features': ['auto', 'sqrt'],\n",
    "             'min_samples_leaf': [1, 2, 4],\n",
    "             'min_samples_split': [2],}]\n",
    "\n",
    "models_regression = {\n",
    "    'lr': {'name': 'Linear Regression',\n",
    "           'estimator': LinearRegression(),\n",
    "           'param': param_lr,\n",
    "          },\n",
    "    'dt': {'name': 'Decision Tree',\n",
    "        'estimator': DecisionTreeRegressor(random_state=42),\n",
    "        'param': param_dt,\n",
    "          },\n",
    "    'rf': {'name': 'Random Forest',\n",
    "           'estimator': RandomForestRegressor(random_state=42),\n",
    "           'param': param_rf,\n",
    "          },\n",
    "    'mlp': {'name': 'Multi Linear Perceptron',\n",
    "            'estimator': MLPRegressor(random_state=42),\n",
    "            'param': param_mlp\n",
    "           },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56deb6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_categories ={'Rock':0,'Classic':1,'Pop':2,'R&B':3,'Country':4,'Electronic':5,'Jazz':6,'Folk':7,'Indie':8,'Metal':9,'Rap':10}\n",
    "    \n",
    "AItechnique_categories ={'searchStartegy':0,'planning':1,'constraints':2}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48c8b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "Permutation explainer: 404it [00:13,  7.94it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling lr\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling lr\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:13,  7.07it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling dt\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling dt\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:53,  3.25it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling rf\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling rf\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:16,  9.74it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling mlp\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling mlp\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyStoryTelling mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "Permutation explainer: 404it [00:13,  7.86it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm lr\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm lr\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:12,  6.96it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm dt\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm dt\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:50,  3.33it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm rf\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm rf\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:19, 10.26it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm mlp\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm mlp\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyRhythm mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "Permutation explainer: 404it [00:14,  8.68it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique lr\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique lr\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:12,  6.94it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique dt\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique dt\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:46,  3.45it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique rf\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique rf\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:19, 10.35it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique mlp\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique mlp\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyMovementTechnique mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "Permutation explainer: 404it [00:13,  7.99it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement lr\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement lr\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:12,  6.99it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement dt\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement dt\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:45,  3.45it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement rf\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement rf\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:17,  9.87it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement mlp\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement mlp\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationPublicInvolvement mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "Permutation explainer: 404it [00:13,  7.66it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace lr\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace lr\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:12,  6.57it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace dt\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace dt\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:50,  3.31it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace rf\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace rf\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:19,  9.71it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace mlp\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace mlp\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographySpace mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "Permutation explainer: 404it [00:15,  9.67it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization lr\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization lr\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:16,  9.61it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization dt\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization dt\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:56,  3.16it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization rf\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization rf\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:18,  9.37it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization mlp\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization mlp\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "Permutation explainer: 404it [00:18, 10.81it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility lr\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility lr\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:12,  7.18it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility dt\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility dt\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:47,  3.41it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility rf\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility rf\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:19, 10.31it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility mlp\n",
      "Saved bar datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility mlp\n",
      "Saved heatmap datasetArtisticBackgroundFINAL.csv EvaluationHumanReproducibility mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "Permutation explainer: 404it [00:13,  7.83it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling lr\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling lr\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:12,  7.12it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling dt\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling dt\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:59,  3.07it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling rf\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling rf\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:20, 10.41it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling mlp\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling mlp\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyStoryTelling mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "Permutation explainer: 404it [00:14,  9.45it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm lr\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm lr\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:16,  9.96it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm dt\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm dt\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:52,  3.25it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm rf\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm rf\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Permutation explainer: 404it [00:18, 10.23it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm mlp\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm mlp\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyRhythm mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "Permutation explainer: 404it [00:13,  7.85it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique lr\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique lr\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:15,  9.78it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique dt\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique dt\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:53,  3.24it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique rf\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique rf\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:18, 10.07it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique mlp\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique mlp\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyMovementTechnique mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "Permutation explainer: 404it [00:14,  8.48it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement lr\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement lr\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:13,  6.89it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement dt\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement dt\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [02:04,  2.97it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement rf\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement rf\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Permutation explainer: 404it [00:25,  9.28it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement mlp\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement mlp\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationPublicInvolvement mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "Permutation explainer: 404it [00:18,  9.89it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace lr\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace lr\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:20, 10.07it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace dt\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace dt\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [02:29,  2.49it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace rf\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace rf\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:17,  9.90it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace mlp\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace mlp\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographySpace mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "Permutation explainer: 404it [00:13,  7.98it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization lr\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization lr\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:12,  6.83it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization dt\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization dt\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:52,  3.24it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization rf\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization rf\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:19,  9.71it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization mlp\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization mlp\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationChoreographyHumanCharacterization mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "Permutation explainer: 404it [00:16, 10.02it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility lr\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility lr\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:15, 10.03it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility dt\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility dt\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [01:52,  3.28it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility rf\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility rf\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 404it [00:21,  9.18it/s]                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved beeswarm datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility mlp\n",
      "Saved bar datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility mlp\n",
      "Saved heatmap datasetScientificBackgroundFINAL.csv EvaluationHumanReproducibility mlp\n"
     ]
    }
   ],
   "source": [
    "for file in fileCSV:\n",
    "    dataset = pd.read_csv(file, sep=';')\n",
    "    X = dataset[['timeDuration', 'nMovements', 'movementsDifficulty', 'AItechnique', 'robotSpeech',    'acrobaticMovements', 'movementsRepetition', 'musicGenre', 'movementsTransitionsDuration', 'humanMovements', 'balance', 'speed', 'bodyPartsCombination', 'musicBPM', 'sameStartEndPositionPlace', 'headMovement', 'armsMovement', 'handsMovement', 'legsMovement', 'feetMovement']]\n",
    "    X.loc[:,'musicGenre']=X.musicGenre.apply(lambda x: music_categories[x])\n",
    "    X.loc[:,'AItechnique']=X.AItechnique.apply(lambda x: AItechnique_categories[x])\n",
    "    index_target= dataset.iloc[:,-7:]    \n",
    "    back = file.split('dataset')[1].split('Background')[0]\n",
    "    \n",
    "    for t in targetName:\n",
    "        list_ind_t = index_target.columns.values.tolist()\n",
    "        targetN = list_ind_t[t]\n",
    "        y = dataset[targetN]\n",
    "        \n",
    "        for m in modelloML:\n",
    "            mod_grid = GridSearchCV(models_regression[m]['estimator'], models_regression[m]['param'], cv=5, return_train_score = False, scoring='neg_mean_squared_error', n_jobs = 8)\n",
    "            data_train, data_test, target_train, target_test = train_test_split(\n",
    "                                                                    X, y, test_size=0.2, random_state=42)\n",
    "            model = mod_grid            \n",
    "            model.fit(data_train, target_train)\n",
    "            \n",
    "            X100 = shap.utils.sample(X, 100)\n",
    "            explainer = shap.Explainer(model.predict,X)\n",
    "            shap_values = explainer(X)\n",
    "\n",
    "            shap.plots.beeswarm(shap_values, show=False)\n",
    "            plt.savefig('Results-%s/Results-%s/%s/Plot/beeswarm.jpg' %(back, m,targetN), bbox_inches='tight')\n",
    "            plt.clf()\n",
    "            plt.cla()\n",
    "            plt.close()\n",
    "            \n",
    "            print(\"Saved beeswarm\",file,targetN,m )\n",
    "            \n",
    "            shap.plots.bar(shap_values, show=False)\n",
    "            plt.savefig('Results-%s/Results-%s/%s/Plot/bar.jpg' %(back, m,targetN), bbox_inches='tight')\n",
    "            plt.clf()\n",
    "            plt.cla()\n",
    "            plt.close()\n",
    "            \n",
    "            print(\"Saved bar\",file,targetN,m )\n",
    "            \n",
    "            shap.plots.heatmap(shap_values, show=False)\n",
    "            plt.savefig('Results-%s/Results-%s/%s/Plot/heatmap.jpg' %(back, m,targetN), bbox_inches='tight')\n",
    "            plt.clf()\n",
    "            plt.cla()\n",
    "            plt.close()\n",
    "            \n",
    "            print(\"Saved heatmap\",file,targetN,m )\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd90df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
